{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Connect to SQL via Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[(10000, 'Christoper Peteuil', 993845, 624, 'Bankhall Ave', 747714076), (10007, 'Kourtney Calderwood', 861794, 2791, 'Gustavus Blvd', 477972044), (10010, 'Muoi Cary', 385336, 741, 'Northwestern Dr', 828638512), (10016, 'Era Moselle', 431897, 1987, 'Wood Glade St', 614621061), (10025, 'Trena Hornby', 550890, 276, 'Daws Hill Way', 223877684)]\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "db_file = (r'files\\sql-murder-mystery.db')\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{db_file}\")\n",
    "# print(db.dialect)\n",
    "# print(db.get_usable_table_names())\n",
    "\n",
    "QUERY = \"SELECT * FROM person LIMIT 5\"\n",
    "\n",
    "db.run(QUERY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Working request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many people are there?\n",
      "\n",
      "SQLQuery: SELECT COUNT(*) FROM person\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_community.llms.ollama import Ollama\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from files.settings import MODEL, MODEL_URL, DB_FILE\n",
    "# Database connection\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{DB_FILE}\")\n",
    "# Ollama model connection via Docker\n",
    "llm = Ollama(model=MODEL, base_url=MODEL_URL)\n",
    "chain = create_sql_query_chain(llm, db)\n",
    "# Static instructions for the model\n",
    "STATIC_MESSAGE = 'You are an experienced data scientist. Answer the question verbally and add the SQL query to prove it. Make the query one line so it is easy to test. Use the simplest and most efficient query'\n",
    "# Main question\n",
    "QUESTION = \"How many people are there?\"\n",
    "# Generate response\n",
    "response = chain.invoke({\"question\": f\"{QUESTION} {STATIC_MESSAGE}\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba osób w bazie danych: [(10011,)]\n"
     ]
    }
   ],
   "source": [
    "# TEST QUERY\n",
    "QUERY = \"SELECT COUNT(*) FROM person\"\n",
    "\n",
    "result = db.run(QUERY)\n",
    "formatted_result = f\"Liczba osób w bazie danych: {result}\"\n",
    "print(formatted_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Connect to LLAMA3 over docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms.ollama import Ollama\n",
    "llm = Ollama(model=MODEL, base_url=MODEL_URL)\n",
    "\n",
    "llm(\"Hello world\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Get table schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "from files.settings import DB_FILE\n",
    "# Database connection\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{DB_FILE}\")\n",
    "\n",
    "schema = db.get_table_info()\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Use prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_community.llms.ollama import Ollama\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from files.settings import MODEL, MODEL_URL, DB_FILE\n",
    "# Database connection\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{DB_FILE}\")\n",
    "# Ollama model connection via Docker\n",
    "llm = Ollama(model=MODEL, base_url=MODEL_URL)\n",
    "chain = create_sql_query_chain(llm, db)\n",
    "# Static instructions for the model\n",
    "STATIC_MESSAGE = 'You are an experienced data scientist. Answer the question verbally and add the SQL query to prove it. Make the query one line so it is easy to test. Use the simplest and most efficient query'\n",
    "# Main question\n",
    "QUESTION = \"How many people are there?\"\n",
    "# Generate response\n",
    "response = chain.invoke({\"question\": f\"{QUESTION} {STATIC_MESSAGE}\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "import db_connect\n",
    "dialect=\"sqlite\"\n",
    "table_info=db_connect.get_schema()\n",
    "# input = \"How many people are there in total?\"\n",
    "\n",
    "template = '''Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer.\n",
    "Use the following format:\n",
    "\n",
    "Question: \"Question here\"\n",
    "SQLQuery: \"SQL Query to run\"\n",
    "SQLResult: \"Result of the SQLQuery\"\n",
    "Answer: \"Final answer here\"\n",
    "\n",
    "Only use the following tables:\n",
    "\n",
    "{table_info}.\n",
    "\n",
    "Question: {input}'''\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "chain = create_sql_query_chain(llm, db, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1> INITIAL TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database, get the schema and connect to the model\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_community.llms.ollama import Ollama\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from files.settings import MODEL, MODEL_URL, DB_FILE\n",
    "# Database connection\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{DB_FILE}\")\n",
    "# Ollama model connection via Docker\n",
    "llm = Ollama(model=MODEL, base_url=MODEL_URL, temperature=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User question\n",
    "question = \"How many people are there in total?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Working prompt template v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working template v1\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import db_connect\n",
    "dialect=\"sqlite\"\n",
    "table_info=db_connect.get_schema()\n",
    "question = \"How many people are there in total?\"\n",
    "\n",
    "template = '''Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer.\n",
    "Use the following format:\n",
    "\n",
    "Question: \"Question here\"\n",
    "SQLQuery: \"SQL Query to run\"\n",
    "SQLResult: \"Result of the SQLQuery\"\n",
    "Answer: \"Final answer here\"\n",
    "\n",
    "Only use the following tables:\n",
    "\n",
    "{table_info}.\n",
    "\n",
    "Question: {input}\n",
    "TopK: {top_k}'''\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "chain = create_sql_query_chain(llm, db, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find the total number of people, we can use a SELECT COUNT statement on the person table. The SQLQuery would be:\n",
      "\n",
      "SELECT COUNT(*) FROM person;\n",
      "\n",
      "The result will be a single row with the count of all rows in the person table. We can then extract this value and return it as the answer to the question.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"question\": question, \"table_info\": table_info, \"dialect\":\"sqlite\", \"top_k\": 1})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working prompt template v2\n",
    "# Build the chain and prompt template\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import db_connect\n",
    "dialect=\"sqlite\"\n",
    "table_info=db_connect.get_schema()\n",
    "question = \"How many people are there in total?\"\n",
    "\n",
    "template = '''Given a question, create a {dialect} query, run it, and return the answer.\n",
    "Format:\n",
    "\n",
    "Question: \"Question here\"\n",
    "SQL: \"SQL Query to run\"\n",
    "Result: \"Result of the SQLQuery\"\n",
    "A: \"Final answer here\"\n",
    "\n",
    "Tables: {table_info}\n",
    "\n",
    "Question: {input}\n",
    "TopK: {top_k}'''\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "chain = create_sql_query_chain(llm, db, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the question and get the response from the model\n",
    "response = chain.invoke({\"question\": question, \"table_info\": table_info, \"dialect\":\"sqlite\", \"top_k\": 1})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Main game<br></h1>\n",
    "A crime has taken place and the detective needs your help. The detective gave you the crime scene report, but you somehow lost it. You vaguely remember that the crime was a ​murder​ that occurred sometime on ​Jan.15, 2018​ and that it took place in ​SQL City​. Start by retrieving the corresponding crime scene report from the police department’s database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>OPTIMIZING LLAMA3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Input:**\n",
      "\n",
      "- **Question:** \"Retrieve murder crime scene report from police department's database from Jan.15, 2018 in SQL City\"\n",
      "- **SQLQuery:** \n",
      "```\n",
      "SELECT * FROM crime_scene_report WHERE date = '20180115' AND type = 'murder';\n",
      "```\n",
      "- **SQLResult:** \n",
      "```\n",
      "date          | type        | description                    | city\n",
      "20180115     | murder      | Life? Dont talk to me about life. | Albany\n",
      "20180115     | murder      | Mama, I killed a man, put a gun against his head... | Reno\n",
      "```\n",
      "- **Answer:** The answer is the two murder crime scene reports from Jan. 15, 2018 in SQL City: \"Life? Dont talk to me about life.\" and \"Mama, I killed a man, put a gun against his head...\"\n"
     ]
    }
   ],
   "source": [
    "# TEST LLAMA3\n",
    "# Build the chain and prompt template\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import db_connect\n",
    "dialect=\"sqlite\"\n",
    "table_info=db_connect.get_schema()\n",
    "\n",
    "template = '''Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer. Use the following format:\n",
    "\n",
    "**Input:**\n",
    "\n",
    "- **Question:** \"Question here\"\n",
    "- **SQLQuery:** \"SQL Query to run\"\n",
    "- **SQLResult:** \"Result of the SQLQuery\"\n",
    "- **Answer:** \"Final answer here\"\n",
    "\n",
    "**Only use the following tables:**\n",
    "\n",
    "{table_info}\n",
    "\n",
    "**Question:** {input}\n",
    "\n",
    "**TopK:** {top_k}\n",
    "'''\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "chain = create_sql_query_chain(llm, db, prompt)\n",
    "\n",
    "# Compressed question v3\n",
    "input = \"Retrieve murder crime scene report from police department's database from jan.15, 2018 in SQL City\"\n",
    "\n",
    "input_data = {\n",
    "    \"question\": input,\n",
    "    \"table_info\": table_info,\n",
    "    \"dialect\": \"sqlite\",\n",
    "    \"top_k\": 1\n",
    "}\n",
    "\n",
    "# Ask the question and get the response from the model\n",
    "response = chain.invoke(input_data)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Game step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Input:**\n",
      "\n",
      "* **Question:** \"The report is from 'SQL City'\".\n",
      "* **SQLQuery:** `SELECT * FROM crime_scene_report WHERE city = 'SQL City';`\n",
      "* **SQLResult:** `date          type         description                city`\n",
      "`20180115      robbery     A Man Dressed as Spider-... SQL City`\n",
      "\n",
      "* **Answer:** \"The report is from 2018-01-15, it's a robbery case in SQL City.\"\n"
     ]
    }
   ],
   "source": [
    "input = \"The report is from 'SQL City'\"\n",
    "input_data = {\n",
    "    \"question\": input,\n",
    "    \"table_info\": table_info,\n",
    "    \"dialect\": \"sqlite\",\n",
    "    \"top_k\": 1\n",
    "}\n",
    "response = chain.invoke(input_data)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Input:**\n",
      "\n",
      "- **Question:** A crime has taken place and the detective needs your help. The detective gave you the crime scene report, but you somehow lost it. You vaguely remember that the crime was a ​murder​ that occurred sometime on ​Jan.15, 2018​ and that it took place in ​SQL City​. Start by retrieving the corresponding crime scene report from the police department’**s database.\n",
      "- **SQLQuery:** SELECT * FROM crime_**scene_report WHERE date = '20180115' AND city = 'NYC' OR city = 'Albany' OR city = 'Reno';\n",
      "- **SQLResult:**\n",
      "date\t\ttype\t\tdescription\t\tcity\n",
      "20180115\tmurder\tMama, I killed a man, put a gun against his head...\tReno\n",
      "\n",
      "**Answer:** The crime scene report for the murder that occurred on Jan. 15, 2018 in SQL City (which is actually Reno) is:\n",
      "\n",
      "Mama, I killed a man, put a gun against his head...\n",
      "\n",
      "Note: Since there are only three rows in the crime_**scene_report table and two of them have city as 'NYC' or 'Albany', we can safely assume that the third row with city as 'Reno' is the one that matches our query.\n"
     ]
    }
   ],
   "source": [
    "# TEST LLAMA3\n",
    "# Build the chain and prompt template\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import db_connect\n",
    "dialect=\"sqlite\"\n",
    "table_info=db_connect.get_schema()\n",
    "\n",
    "template = '''Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer. Use the following format:\n",
    "\n",
    "**Input:**\n",
    "\n",
    "- **Question:** \"Question here\"\n",
    "- **SQLQuery:** \"SQL Query to run\"\n",
    "- **SQLResult:** \"Result of the SQLQuery\"\n",
    "- **Answer:** \"Final answer here\"\n",
    "\n",
    "**Only use the following tables:**\n",
    "\n",
    "{table_info}\n",
    "\n",
    "**Question:** {input}\n",
    "\n",
    "**TopK:** {top_k}\n",
    "'''\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "chain = create_sql_query_chain(llm, db, prompt)\n",
    "\n",
    "# Compressed question v3\n",
    "input = \"A crime has taken place and the detective needs your help. The detective gave you the crime scene report, but you somehow lost it. You vaguely remember that the crime was a ​murder​ that occurred sometime on ​Jan.15, 2018​ and that it took place in ​SQL City​. Start by retrieving the corresponding crime scene report from the police department’s database.\"\n",
    "\n",
    "input_data = {\n",
    "    \"question\": input,\n",
    "    \"table_info\": table_info,\n",
    "    \"dialect\": \"sqlite\",\n",
    "    \"top_k\": 1\n",
    "}\n",
    "\n",
    "# Ask the question and get the response from the model\n",
    "response = chain.invoke(input_data)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>LOCAL OLLAMA PERFORMANCE COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Input:**\n",
      "\n",
      "* **Question:** \"A crime has taken place and the detective needs your help. The detective gave you the crime scene report, but you somehow lost it. You vaguely remember that the crime was a ​murder​ that occurred sometime on ​Jan.15, 2018​ and that it took place in ​SQL City​. Start by retrieving the corresponding crime scene report from the police department’­s database.\"\n",
      "* **SQLQuery:** \"SELECT * FROM crime_scene_report WHERE type='murder' AND date BETWEEN '20180114' AND '20180116';\"\n",
      "* **SQLResult:**\n",
      "| date       | type    | description                    | city        |\n",
      "|------------|---------|-------------------------------|-------------|\n",
      "| 20180115   | murder  | Life? Dont talk to me about life. | Albany      |\n",
      "\n",
      "* **Answer:** \"The crime scene report for the murder that occurred on Jan.15, 2018 in Albany.\"\n",
      "Czas wykonania: 7.431161880493164 sekund.\n"
     ]
    }
   ],
   "source": [
    "# LOCAL OLLAMA\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "# from langchain_community.llms.ollama import Ollama\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.chains import create_sql_query_chain\n",
    "\n",
    "from files.settings import DB_FILE\n",
    "\n",
    "import db_connect\n",
    "\n",
    "# Database connection\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{DB_FILE}\")\n",
    "# Ollama model connection via Docker\n",
    "llm = ChatOllama(model=\"llama3\")\n",
    "dialect=\"sqlite\"\n",
    "table_info=db_connect.get_schema()\n",
    "\n",
    "template = '''Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer. Use the following format:\n",
    "\n",
    "**Input:**\n",
    "\n",
    "- **Question:** \"Question here\"\n",
    "- **SQLQuery:** \"SQL Query to run\"\n",
    "- **SQLResult:** \"Result of the SQLQuery\"\n",
    "- **Answer:** \"Final answer here\"\n",
    "\n",
    "**Only use the following tables:**\n",
    "\n",
    "{table_info}\n",
    "\n",
    "**Question:** {input}\n",
    "\n",
    "**TopK:** {top_k}\n",
    "'''\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "chain = create_sql_query_chain(llm, db, prompt)\n",
    "\n",
    "# Compressed question v3\n",
    "input = \"A crime has taken place and the detective needs your help. The detective gave you the crime scene report, but you somehow lost it. You vaguely remember that the crime was a ​murder​ that occurred sometime on ​Jan.15, 2018​ and that it took place in ​SQL City​. Start by retrieving the corresponding crime scene report from the police department’s database.\"\n",
    "\n",
    "input_data = {\n",
    "    \"question\": input,\n",
    "    \"table_info\": table_info,\n",
    "    \"dialect\": \"sqlite\",\n",
    "    \"top_k\": 1\n",
    "}\n",
    "\n",
    "import time\n",
    "\n",
    "# Rozpoczęcie pomiaru czasu\n",
    "start_time = time.time()\n",
    "\n",
    "# Ask the question and get the response from the model\n",
    "response = chain.invoke(input_data)\n",
    "print(response)\n",
    "\n",
    "# Zakończenie pomiaru czasu\n",
    "end_time = time.time()\n",
    "\n",
    "# Wyświetlenie czasu wykonania\n",
    "print(f\"Czas wykonania: {end_time - start_time} sekund.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Input:**\n",
      "\n",
      "* **Question:** A crime has taken place and the detective needs your help. The detective gave you the crime scene report, but you somehow lost it. You vaguely remember that the crime was a ​murder​ that occurred sometime on ​Jan.15, 2018​ and that it took place in ​SQL City​. Start by retrieving the corresponding crime scene report from the police department’­s database.\n",
      "* **SQLQuery:** SELECT * FROM crime_­scene_­report WHERE date = '20180115' AND city = 'Albany' OR city = 'Reno';\n",
      "* **SQLResult:**\n",
      "\t+ date\t| type\t| description\t\t\t| city\n",
      "\t+ 20180115 | murder | Life? Dont talk to me about life. | Albany\n",
      "\t+ 20180115 | murder | Mama, I killed a man, put a gun against his head... | Reno\n",
      "\n",
      "**Answer:** The crime scene report for the murder that occurred on Jan. 15, 2018 in either Albany or Reno is:\n",
      "\n",
      "date: 20180115\n",
      "type: murder\n",
      "description: Life? Dont talk to me about life.\n",
      "city: Albany\n",
      "\n",
      "OR\n",
      "\n",
      "date: 20180115\n",
      "type: murder\n",
      "description: Mama, I killed a man, put a gun against his head...\n",
      "city: Reno\n",
      "Czas wykonania: 144.6903805732727 sekund.\n"
     ]
    }
   ],
   "source": [
    "# DOCKER OLLAMA\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_community.llms.ollama import Ollama\n",
    "from langchain.chains import create_sql_query_chain\n",
    "\n",
    "from files.settings import DB_FILE, MODEL, MODEL_URL\n",
    "\n",
    "import db_connect\n",
    "\n",
    "# Database connection\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{DB_FILE}\")\n",
    "# Ollama model connection via Docker\n",
    "llm = Ollama(model=MODEL, base_url=MODEL_URL)\n",
    "dialect=\"sqlite\"\n",
    "table_info=db_connect.get_schema()\n",
    "\n",
    "template = '''Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer. Use the following format:\n",
    "\n",
    "**Input:**\n",
    "\n",
    "- **Question:** \"Question here\"\n",
    "- **SQLQuery:** \"SQL Query to run\"\n",
    "- **SQLResult:** \"Result of the SQLQuery\"\n",
    "- **Answer:** \"Final answer here\"\n",
    "\n",
    "**Only use the following tables:**\n",
    "\n",
    "{table_info}\n",
    "\n",
    "**Question:** {input}\n",
    "\n",
    "**TopK:** {top_k}\n",
    "'''\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "chain = create_sql_query_chain(llm, db, prompt)\n",
    "\n",
    "# Compressed question v3\n",
    "input = \"A crime has taken place and the detective needs your help. The detective gave you the crime scene report, but you somehow lost it. You vaguely remember that the crime was a ​murder​ that occurred sometime on ​Jan.15, 2018​ and that it took place in ​SQL City​. Start by retrieving the corresponding crime scene report from the police department’s database.\"\n",
    "\n",
    "input_data = {\n",
    "    \"question\": input,\n",
    "    \"table_info\": table_info,\n",
    "    \"dialect\": \"sqlite\",\n",
    "    \"top_k\": 1\n",
    "}\n",
    "\n",
    "import time\n",
    "\n",
    "# Rozpoczęcie pomiaru czasu\n",
    "start_time = time.time()\n",
    "\n",
    "# Ask the question and get the response from the model\n",
    "response = chain.invoke(input_data)\n",
    "print(response)\n",
    "\n",
    "# Zakończenie pomiaru czasu\n",
    "end_time = time.time()\n",
    "\n",
    "# Wyświetlenie czasu wykonania\n",
    "print(f\"Czas wykonania: {end_time - start_time} sekund.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
